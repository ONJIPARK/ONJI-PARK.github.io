---
layout: single
title:  "12th Week Course-3"
categories: coding
tag: [python, blog, jupyter, LSA]
toc: true
author_profile: false
---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>


# LSA


#### DTM 만들기



```python
import numpy as np
A=np.array([[0,0,0,1,0,1,1,0,0],[0,0,0,1,1,0,1,0,0],[0,1,1,0,2,0,0,0,0],[1,0,0,0,0,0,0,1,1]])
np.shape(A)
```

<pre>
(4, 9)
</pre>
#### SVD



```python
U, s, VT = np.linalg.svd(A, full_matrices = True) # 시그마 대신 s를 사용. 총 세 개의 행렬
```


```python
print(U.round(2)) # 소수 둘째자리에서 반올림
np.shape(U)
```

<pre>
[[ 0.24  0.75  0.    0.62]
 [ 0.51  0.44 -0.   -0.74]
 [ 0.83 -0.49 -0.    0.27]
 [ 0.   -0.    1.   -0.  ]]
</pre>
<pre>
(4, 4)
</pre>

```python
# Numpy의 linalg.svd()는 특이값 분해의 결과로 대각 행렬이 아니라 특이값의 리스트를 반환
print(s.round(2))
np.shape(s)
```

<pre>
[2.69 2.05 1.73 0.77]
</pre>
<pre>
(4,)
</pre>

```python
# 다시 대각 행렬로 바꾸어 주어야 함
S = np.zeros((4, 9)) # 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성
S[:4, :4] = np.diag(s) # 특이값을 대각행렬에 삽입
print(S.round(2))
np.shape(S)
```

<pre>
[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]
 [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]
 [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]
</pre>
<pre>
(4, 9)
</pre>

```python
print(VT.round(2)) # 직교 행렬 VT(V의 전치 행렬)
np.shape(VT)
```

<pre>
[[ 0.    0.31  0.31  0.28  0.8   0.09  0.28  0.    0.  ]
 [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]
 [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]
 [-0.    0.35  0.35 -0.16 -0.25  0.8  -0.16  0.    0.  ]
 [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]
 [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]
 [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]
 [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]
 [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]
</pre>
<pre>
(9, 9)
</pre>

```python
# U × S × VT를 하면 기존의 행렬 A가 나오는지 확인
np.allclose(A, np.dot(np.dot(U,S), VT).round(2))
```

<pre>
True
</pre>
#### Truncated SVD (t=2)



```python
S=S[:2,:2]
print(S.round(2))
```

<pre>
[[2.69 0.  ]
 [0.   2.05]]
</pre>

```python
U=U[:,:2]
print(U.round(2))
```

<pre>
[[ 0.24  0.75]
 [ 0.51  0.44]
 [ 0.83 -0.49]
 [ 0.   -0.  ]]
</pre>

```python
VT=VT[:2,:]
print(VT.round(2))
```

<pre>
[[ 0.    0.31  0.31  0.28  0.8   0.09  0.28  0.    0.  ]
 [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]
</pre>
#### U × S × VT연산을 통해 기존 행렬과의 비교



```python
A_prime=np.dot(np.dot(U,S), VT)  # 행렬이 줆. 줄어들었다는 건 그만큼 가지고 있는 정보가 줄었다는 것.
print(A)                         # 그러면서도 행렬이 비슷하다면 줄어든 모델이 좋은 설명력을 가진다는 것
print(A_prime.round(2))
```

<pre>
[[0 0 0 1 0 1 1 0 0]
 [0 0 0 1 1 0 1 0 0]
 [0 1 1 0 2 0 0 0 0]
 [1 0 0 0 0 0 0 1 1]]
[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]
 [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]
 [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]
</pre>

```python
```

## 실습 예제2



```python
import pandas as pd
from konlpy.tag import Okt

df = pd.read_csv('data/job_review.csv')
df[:5] # 상위 5개 출력
```

<pre>
C:\Users\Administrator\anaconda3\lib\site-packages\IPython\core\interactiveshell.py:3165: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.
  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
</pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>industry</th>
      <th>name</th>
      <th>numofreviews</th>
      <th>job</th>
      <th>status</th>
      <th>location</th>
      <th>date</th>
      <th>rate</th>
      <th>promotion</th>
      <th>...</th>
      <th>managers</th>
      <th>title</th>
      <th>pros</th>
      <th>len_pros</th>
      <th>cons</th>
      <th>len_cons</th>
      <th>hope_to_mgr</th>
      <th>growth</th>
      <th>recommendation</th>
      <th>stock_code</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1000</td>
      <td>대한민국 육군</td>
      <td>782</td>
      <td>특수계층/공공</td>
      <td>전직원</td>
      <td>강원</td>
      <td>2017-11-28</td>
      <td>3</td>
      <td>3</td>
      <td>...</td>
      <td>3</td>
      <td>"어느직장이나 그렇겟지만 부대의 위치와 지휘관급들의 성향에따라 극과 극을 달릴수 있다."</td>
      <td>휴가같은 경우는 자신의 상관의 성향에 따라 정말 극과극을달리고 월급이나 추가수당 걱...</td>
      <td>14</td>
      <td>많이 나아졌다고는 하나 지휘관 급들의 생각이 틀에박혀있고 불필요하고 비효율적인 행위...</td>
      <td>12</td>
      <td>겉보기식의 생활, 복지개선이아니라 실질적인것들에 대해 개선이 이루어졌으면 함.</td>
      <td>0</td>
      <td>1</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1000</td>
      <td>대한민국 육군</td>
      <td>782</td>
      <td>경영/기획/컨설팅</td>
      <td>전직원</td>
      <td>인천</td>
      <td>2017-11-16</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>5</td>
      <td>"장교로서 근무지가 3군수지원 사령부의 경우\r\n군수지원부대의 메카중하나이나\r\...</td>
      <td>군관사공급을 통한주거안정, 월급의 안정성, 대출받기 쉬움</td>
      <td>6</td>
      <td>명확하지 않은 업무지시, 하급자 책임전가\r\n상습적인 인격모독, 성희롱, 성범죄 등등</td>
      <td>9</td>
      <td>법대로 좀 해라, 맨날 말로만 규정과 방침강조,\r\n고급장교들의 책임회피, 허술한...</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1000</td>
      <td>대한민국 육군</td>
      <td>782</td>
      <td>인사/총무</td>
      <td>전직원</td>
      <td>경기</td>
      <td>2017-11-13</td>
      <td>3</td>
      <td>2</td>
      <td>...</td>
      <td>1</td>
      <td>"애국심과 군인정신이 본인의 가치관과 맞지않으면 근무하기 힘드나 국방수호라는 보람을...</td>
      <td>관사와 식비 제공으로 미혼기준으로 월 100이상 모으는게 어렵지 않음.\r\n공무원...</td>
      <td>20</td>
      <td>불규칙한 야근이 잦고 일일 초과근무 시간이 제한되어 있어 새벽까지 업무를 하는 경우...</td>
      <td>31</td>
      <td>날이 갈 수록 근무여건이 좋아지고 있지만, 전역간부로서 병사들에게 랜턴과 배터리 지...</td>
      <td>1</td>
      <td>0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>1000</td>
      <td>대한민국 육군</td>
      <td>782</td>
      <td>특수계층/공공</td>
      <td>현직원</td>
      <td>경기</td>
      <td>2017-11-12</td>
      <td>2</td>
      <td>3</td>
      <td>...</td>
      <td>3</td>
      <td>"사명감과 희생정신으로 확고히 무장된 사람이 아니라면 버티기 힘들며 사교성과 인간관...</td>
      <td>공직이므로 휴일은 칼같이 보장됨.훈련등으로 휴일출근 시 전투휴무로 평일에 휴식할 수...</td>
      <td>20</td>
      <td>경직된 조직문화, 상급자의 부당한 지시에 목소리를 낼 수 없음, 고질적인 인력부족,...</td>
      <td>13</td>
      <td>고칠건 고쳐나가야 한다. 현재있는 사람의 소중함을 느끼고 인격적으로 대우하기를</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>1000</td>
      <td>대한민국 육군</td>
      <td>782</td>
      <td>전문직</td>
      <td>현직원</td>
      <td>대구</td>
      <td>2017-11-11</td>
      <td>3</td>
      <td>2</td>
      <td>...</td>
      <td>4</td>
      <td>"사회에서 배우지 못하는것을 많이 배웁니다\r\n군대라는 사회라 참 보수적이며 사람...</td>
      <td>모든것을 배울수있습니다\r\n현장작업,인사,군수,협조등 전투기술이외 많이 배울수있습니다</td>
      <td>5</td>
      <td>비합리적인 인사제도(출신과비출신), 매우보수적인사회,\r\n계급으로 인한 비평등사회...</td>
      <td>11</td>
      <td>혁신적이고 자유로운 군대로 바뀌어야합니다\r\n좀더 사람을 위한 운용을 해주십시요</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 23 columns</p>
</div>



```python
df = df.dropna() #결측치 제거
```


```python
okt=Okt() 
noun_list = []
detokenized_doc = []

for sentence in df.cons:
    noun_list = okt.nouns(sentence)
    noun_list = [n for n in noun_list if len(n) > 1]
    t = ' '.join(noun_list)
    detokenized_doc.append(t)
    
df.txt = detokenized_doc
```

<pre>
<ipython-input-17-2a355adbb27c>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access
  df.txt = detokenized_doc
</pre>

```python
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features= 1000, # 상위 1,000개의 단어를 보존 
                             max_df = 0.5, smooth_idf=True)
                            # 너무 등장하는 단어에 제한
X = vectorizer.fit_transform(df.txt)
X.shape # TF-IDF 행렬의 크기 확인
```

<pre>
(13911, 1000)
</pre>

```python
from sklearn.decomposition import TruncatedSVD
svd_model = TruncatedSVD(n_components=5, algorithm='randomized', n_iter=100, random_state=122)# 개의 주제로 만들어라
svd_model.fit(X)
len(svd_model.components_)

np.shape(svd_model.components_)

terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.

def get_topics(components, feature_names, n=5):
    for idx, topic in enumerate(components):
        print("Topic %d:" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])
get_topics(svd_model.components_,terms)

# 13911개의 데이터를 5개의 주제로
```

<pre>
Topic 1: [('업무', 0.42338), ('연봉', 0.27214), ('강도', 0.24827), ('문화', 0.24172), ('야근', 0.22691)]
Topic 2: [('업무', 0.63534), ('강도', 0.47356), ('부서', 0.09181), ('스트레스', 0.03821), ('효율', 0.0328)]
Topic 3: [('연봉', 0.78204), ('복지', 0.14738), ('승률', 0.07415), ('대비', 0.06694), ('수준', 0.06609)]
Topic 4: [('야근', 0.4395), ('사람', 0.25557), ('회사', 0.22711), ('시간', 0.18223), ('부서', 0.14451)]
Topic 5: [('야근', 0.5718), ('문화', 0.2579), ('연봉', 0.17252), ('시간', 0.15461), ('군대', 0.14976)]
</pre>

```python
```


```python
```


```python
```

### 실습 예제3


#### 1) 뉴스그룹 데이터에 대한 이해



```python
import pandas as pd
from sklearn.datasets import fetch_20newsgroups
dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))
documents = dataset.data
len(documents)
```

<pre>
11314
</pre>

```python
documents[1]
```

<pre>
"\n\n\n\n\n\n\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\nof steam!\n\n\n\n\n\n\n\nJim,\n\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\ndenial about the faith you need to get by.  Oh well, just pretend that it will\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\nalt.atheist.hard, you won't be bummin' so much?\n\n\n\n\n\n\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \n--\nBake Timmons, III"
</pre>

```python
dataset.target_names # target_name에는 카테고리가 표시
```

<pre>
['alt.atheism',
 'comp.graphics',
 'comp.os.ms-windows.misc',
 'comp.sys.ibm.pc.hardware',
 'comp.sys.mac.hardware',
 'comp.windows.x',
 'misc.forsale',
 'rec.autos',
 'rec.motorcycles',
 'rec.sport.baseball',
 'rec.sport.hockey',
 'sci.crypt',
 'sci.electronics',
 'sci.med',
 'sci.space',
 'soc.religion.christian',
 'talk.politics.guns',
 'talk.politics.mideast',
 'talk.politics.misc',
 'talk.religion.misc']
</pre>
#### 2) 텍스트 전처리



```python
news_df = pd.DataFrame({'document':documents})
# 특수 문자 제거
news_df['clean_doc'] = news_df['document'].str.replace("[^a-zA-Z]", " ")
# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)
news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))
# 전체 단어에 대한 소문자 변환
news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())
```

<pre>
<ipython-input-23-b4124dfb5e6a>:3: FutureWarning: The default value of regex will change from True to False in a future version.
  news_df['clean_doc'] = news_df['document'].str.replace("[^a-zA-Z]", " ")
</pre>

```python
news_df['clean_doc'][1]
```

<pre>
'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'
</pre>

```python
!pip install stopwords
!pip install nltk
```

<pre>
Requirement already satisfied: stopwords in c:\users\administrator\anaconda3\lib\site-packages (1.0.0)
Requirement already satisfied: nltk in c:\users\administrator\anaconda3\lib\site-packages (3.6.1)
Requirement already satisfied: joblib in c:\users\administrator\anaconda3\lib\site-packages (from nltk) (1.0.1)
Requirement already satisfied: regex in c:\users\administrator\anaconda3\lib\site-packages (from nltk) (2021.4.4)
Requirement already satisfied: tqdm in c:\users\administrator\anaconda3\lib\site-packages (from nltk) (4.59.0)
Requirement already satisfied: click in c:\users\administrator\anaconda3\lib\site-packages (from nltk) (7.1.2)
</pre>

```python
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')
stop_words = stopwords.words('english') # NLTK로부터 불용어를 받아옵니다.
tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화
tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])
# 불용어를 제거합니다.
```

<pre>
[nltk_data] Downloading package stopwords to
[nltk_data]     C:\Users\Administrator\AppData\Roaming\nltk_data...
[nltk_data]   Unzipping corpora\stopwords.zip.
</pre>

```python
print(tokenized_doc[1]) # 토큰화
```

<pre>
['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']
</pre>
#### 3) TF-IDF 행렬 만들기



```python
# 역토큰화 (토큰화 작업을 역으로 되돌림)
detokenized_doc = []
for i in range(len(news_df)):
    t = ' '.join(tokenized_doc[i])
    detokenized_doc.append(t)

news_df['clean_doc'] = detokenized_doc
```


```python
news_df['clean_doc'][1]
```

<pre>
'yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgroup atheist hard bummin much forget flintstone chewables bake timmons'
</pre>

```python
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000, # 상위 1,000개의 단어를 보존 
                             max_df = 0.5, smooth_idf=True)

X = vectorizer.fit_transform(news_df['clean_doc'])
X.shape # TF-IDF 행렬의 크기 확인
```

<pre>
(11314, 1000)
</pre>
#### 4) 토픽 모델링



```python
from sklearn.decomposition import TruncatedSVD
svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)
svd_model.fit(X)
len(svd_model.components_)
```

<pre>
20
</pre>

```python
np.shape(svd_model.components_)
```

<pre>
(20, 1000)
</pre>

```python
terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.

def get_topics(components, feature_names, n=5):
    for idx, topic in enumerate(components):
        print("Topic %d:" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])
get_topics(svd_model.components_,terms)

# 앞에 있는 단어일수록 그 토픽에 많이 기여했다는 것임
```

<pre>
Topic 1: [('like', 0.21386), ('know', 0.20046), ('people', 0.19293), ('think', 0.17805), ('good', 0.15128)]
Topic 2: [('thanks', 0.32888), ('windows', 0.29088), ('card', 0.18069), ('drive', 0.17455), ('mail', 0.15111)]
Topic 3: [('game', 0.37064), ('team', 0.32443), ('year', 0.28154), ('games', 0.2537), ('season', 0.18419)]
Topic 4: [('drive', 0.53324), ('scsi', 0.20165), ('hard', 0.15628), ('disk', 0.15578), ('card', 0.13994)]
Topic 5: [('windows', 0.40399), ('file', 0.25436), ('window', 0.18044), ('files', 0.16078), ('program', 0.13894)]
Topic 6: [('chip', 0.16114), ('government', 0.16009), ('mail', 0.15625), ('space', 0.1507), ('information', 0.13562)]
Topic 7: [('like', 0.67086), ('bike', 0.14236), ('chip', 0.11169), ('know', 0.11139), ('sounds', 0.10371)]
Topic 8: [('card', 0.46633), ('video', 0.22137), ('sale', 0.21266), ('monitor', 0.15463), ('offer', 0.14643)]
Topic 9: [('know', 0.46047), ('card', 0.33605), ('chip', 0.17558), ('government', 0.1522), ('video', 0.14356)]
Topic 10: [('good', 0.42756), ('know', 0.23039), ('time', 0.1882), ('bike', 0.11406), ('jesus', 0.09027)]
Topic 11: [('think', 0.78469), ('chip', 0.10899), ('good', 0.10635), ('thanks', 0.09123), ('clipper', 0.07946)]
Topic 12: [('thanks', 0.36824), ('good', 0.22729), ('right', 0.21559), ('bike', 0.21037), ('problem', 0.20894)]
Topic 13: [('good', 0.36212), ('people', 0.33985), ('windows', 0.28385), ('know', 0.26232), ('file', 0.18422)]
Topic 14: [('space', 0.39946), ('think', 0.23258), ('know', 0.18074), ('nasa', 0.15174), ('problem', 0.12957)]
Topic 15: [('space', 0.31613), ('good', 0.3094), ('card', 0.22603), ('people', 0.17476), ('time', 0.14496)]
Topic 16: [('people', 0.48156), ('problem', 0.19961), ('window', 0.15281), ('time', 0.14664), ('game', 0.12871)]
Topic 17: [('time', 0.34465), ('bike', 0.27303), ('right', 0.25557), ('windows', 0.1997), ('file', 0.19118)]
Topic 18: [('time', 0.5973), ('problem', 0.15504), ('file', 0.14956), ('think', 0.12847), ('israel', 0.10903)]
Topic 19: [('file', 0.44163), ('need', 0.26633), ('card', 0.18388), ('files', 0.17453), ('right', 0.15448)]
Topic 20: [('problem', 0.33006), ('file', 0.27651), ('thanks', 0.23578), ('used', 0.19206), ('space', 0.13185)]
</pre>

```python
```
